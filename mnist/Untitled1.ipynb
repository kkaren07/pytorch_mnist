{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat dog_akaze.py | pbcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'train_set'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d3782f22696f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-d3782f22696f>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0mtrain_img_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;31m#train_label_list = []\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m     \u001b[0merr_trainset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../mnist/list.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlist_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'train_set'"
     ]
    }
   ],
   "source": [
    "import train_mnist as train_mn\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import pickle\n",
    "import os.path\n",
    "\n",
    "#%matplotlib inline\n",
    "\n",
    "def get_mnist():\n",
    "    batch_size = 100\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Normalize((0.5, ), (0.5, ))])\n",
    "    trainset = torchvision.datasets.MNIST(root='../mnist/data_mnist', train=True, download=True, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    testset = torchvision.datasets.MNIST(root='../mnist/data_mnist', train=False, download=True, transform=transform)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    err_labels = load_data.put_error\n",
    "    #return trainloader\n",
    "    return trainloader, trainset\n",
    "\n",
    "def give_trainimg():\n",
    "    trainset = get_mnist()\n",
    "    for (img, label) in trainset:\n",
    "        dog = before_DoG(img)\n",
    "#k_size->kernel size, k->constant to scale\n",
    "def DoG(img, k_size, sigma, k):\n",
    "    sigma_large = sigma * k\n",
    "    G_small = cv2.GaussianBlur(img, k_size, sigma)\n",
    "    G_large = cv2.GaussianBlur(img, k_size, sigma_large)\n",
    "    D = G_small - G_large\n",
    "    return D\n",
    "\n",
    "def preprocessing(img):\n",
    "    img = cv2.resize(img, (28, 28))\n",
    "    return img\n",
    "\n",
    "def extract_feature(img_test, img_train):\n",
    "    # find the keypoints and descriptors\n",
    "    # 特徴点に対して特徴記述子(descriptor)を計算\n",
    "    kp_test, des_test = cv2.img_test.detectAndCompute(img_test, None)\n",
    "    kp_train, des_train = cv2.img_train.detectAndCompute(img_train, None)\n",
    "    # 記述子を比較して近いものからマッチング\n",
    "    matches = bf.match(des_test, des_train)\n",
    "    # distanceは近い程よい\n",
    "    dist = [m.distance for m in matches]\n",
    "    ret = sum(dist) / len(dist)\n",
    "    return(ret, img_train)\n",
    "\n",
    "\n",
    "def extract_feature(img_test, img_train):\n",
    "    img_train = img_train.numpy()\n",
    "    dist = np.linalg.norm(img_test - img_train)\n",
    "    return(dist, img_train)\n",
    "\n",
    "def before_DoG(torch_img):#torch_img->tensor\n",
    "    np_images_one = torch_img.numpy()\n",
    "    # [c, h, w] => [h, w, c]\n",
    "    np_images = np.transpose(np_images_one, (1, 2, 0))\n",
    "    np_images = np_images.astype('uint8')\n",
    "    k_size = (3,3)\n",
    "    sigma = 1.3\n",
    "    k = 1.6\n",
    "    dog = DoG(np_images, k_size, sigma, k)\n",
    "    return(dog, np_images_one)\n",
    "   \n",
    "def get_pass_img(test_miss_mnist, train_mnist_set):\n",
    "    ret_list = []\n",
    "    for img_num in range(60000):\n",
    "        # train_mnist = preprocessing(train_mnist_set.train_data[img_num])\n",
    "        train_mnist = train_mnist_set.train_data[img_num]\n",
    "        ret, img_train = extract_feature(test_miss_mnist, train_mnist)\n",
    "        ret_list.append({'distance' : ret, 'img' : img_train})\n",
    "    ret_list_sort = sorted(ret_list, reverse=True, key=lambda x:x['distance']) # distance is sorted\n",
    "    return(ret_list_sort)\n",
    "\n",
    "def subplot(ret_list_top10, test_img, k, err_trainset):\n",
    "    print('this is uncorrect image')\n",
    "    #plt.imshow(test_img.reshape(28,28))\n",
    "    plt.imshow(test_img)\n",
    "    #str_file_1 = '%03.f'%(num)+'.png'\n",
    "    #path_file_1 = os.path.join('./uncorrect_img',str_file_1)\n",
    "    #plt.savefig(path_file_1)\n",
    "    plt.show()\n",
    "    for i in range(10):\n",
    "        train_img = ret_list_top10[i]['img']\n",
    "        distance = ret_list_top10[i]['distance']\n",
    "        # fig = plt.figure()\n",
    "        for j in err_trainset:\n",
    "            if ret_list_top10[i]['train_idx']==err_trainset[j]:\n",
    "                print('this is a trainimage with the wrong tag')\n",
    "        print('distance : ',distance)\n",
    "        print(train_img.shape)\n",
    "        #plt.imshow(train_img.reshape(28,28))\n",
    "        plt.imshow(train_img)\n",
    "        #str_file_2 = '%03.f'%(k)+'.png'\n",
    "        #path_file_2 = os.path.join('./similar_img',str_file_2)\n",
    "        #plt.savefig(path_file_2)\n",
    "        k = k+1\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        \n",
    "def akaze(test_img, train_mnist_set):\n",
    "    detector = cv2.AKAZE_create()\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING)\n",
    "    #print(type(test_img))\n",
    "    test_img = test_img.numpy()\n",
    "    #print(type(test_img))\n",
    "    test_img = np.transpose(test_img, (1, 2, 0))\n",
    "    test_img = test_img.astype('uint8')\n",
    "    test_img = cv2.resize(test_img, (200,200))#detectAndComputeの戻り値がNoneではなくなった！\n",
    "    (test_kp, test_des) = detector.detectAndCompute(test_img, None)\n",
    "    matches_list = []\n",
    "    for img_num in range(60000):\n",
    "        train_mnist = train_mnist_set[img_num]\n",
    "        train_mnist = train_mnist.numpy()\n",
    "        train_mnist = np.transpose(train_mnist, (1, 2, 0))\n",
    "        train_mnist = train_mnist.astype('uint8')\n",
    "        train_mnist = cv2.resize(train_mnist, (200,200))\n",
    "        (train_kp, train_des) = detector.detectAndCompute(train_mnist, None)\n",
    "        matches = bf.match(train_des, test_des)\n",
    "        #dist = [m.distance for m in matches]\n",
    "        #ret = sum(dist) / len(dist)\n",
    "        matches_list.append({'distance' : matches[img_num].distance, 'img' : train_mnist, 'train_idx' : img_num})\n",
    "        #print(matches_list)\n",
    "        \n",
    "    matches_list = sorted(matches_list,  key = lambda x:x['distance'])\n",
    "    return(matches_list, test_img)\n",
    "    \n",
    "def main():\n",
    "    k=0\n",
    "    train_img_list = []\n",
    "    #train_label_list = []\n",
    "    err_trainset = train_mn.train.train_set\n",
    "    with open('../mnist/list.txt', mode='rb') as list_result:\n",
    "        data = pickle.load(list_result)\n",
    "    for dec in data:\n",
    "        if dec['label'] != dec['predict']:\n",
    "            torch_img = torch.tensor(dec['image'])\n",
    "            trainloader, trainset = get_mnist()\n",
    "            for batch_idx, (images, labels) in enumerate(trainloader):\n",
    "                for idx in range(len(images)):\n",
    "                    train_img_list.append(images[idx])\n",
    "                    #train_label_list.append(labels[idx])\n",
    "            #test_miss_mnist = preprocessing(test_miss_mnist)\n",
    "            #cv2.imwrite('output.jpg', test_miss_mnist)\n",
    "            \n",
    "            # for DoG\n",
    "            #test_miss_mnist, not_dog_img = before_DoG(torch_img)\n",
    "            #ret_list_sort = get_pass_img(test_miss_mnist, train_mnist_set)\n",
    "            #ret_list_top10 = ret_list_sort[:10]\n",
    "            #subplot(ret_list_top10, not_dog_img)\n",
    "            \n",
    "            # for AKAZE\n",
    "            matches,test_img = akaze(torch_img, train_img_list)\n",
    "            matches = matches[:10]\n",
    "            subplot(matches, test_img, k, err_trainset)\n",
    "            k=k+10\n",
    "  \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
